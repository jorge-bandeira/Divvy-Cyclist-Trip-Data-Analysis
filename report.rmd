---
title: "Cyclist Trip Data Analysis"
author: "Jorge Bandeira"
date: "`r Sys.Date()`"
output: html_document
---

## 1. Introduction

This analysis was performed on a fictional company as part of a capstone project for Google's Data Analyst Certification.

Cyclist is a bike sharing company in Chicago. Most of Cyclist’s revenue comes from its annual members. Therefore, focusing on converting casual users to annual subscribers was determined as the best strategy to increase growth.

A starting point would be to identify the differences between casual and annual subscribers and that is the main goal of this analysis.

Using data to determine the key differences between both type of users should provide the marketing team with insights into what aspects should be targeted to attract more annual customers.

## 2. Preparation

The data for this analysis was downloaded from an [aws repository](https://divvy-tripdata.s3.amazonaws.com/index.html) where it was made available by Motivate International Inc. under the following [licence](https://ride.divvybikes.com/data-license-agreement)

The data, consisting of twelve csv files, was copied to two separate folders named trip_data_raw and trip_data. The first folder serves the purpose of keeping unaltered, original copies of the data. The second folder holds copies meant to be cleaned and transformed for analysis.

By sorting and filtering the data it was detected that there were some problems that would be need to be adressed in the cleaning process such as empty station names and ids.

## 3. Process

Due to the large amount of data available, R was selected as the tool to perform both the cleaning and analysis process.
All twelve csv files were imported into an R project to begin the data cleaning process.

```{r eval=FALSE, results='hide'}
library(tidyverse)
Jun_21 <- read.csv("data/trip_data/202106-divvy-tripdata.csv")
Jul_21 <- read.csv("data/trip_data/202107-divvy-tripdata.csv")
Aug_21 <- read.csv("data/trip_data/202108-divvy-tripdata.csv")
Sep_21 <- read.csv("data/trip_data/202109-divvy-tripdata.csv")
Oct_21 <- read.csv("data/trip_data/202110-divvy-tripdata.csv")
Nov_21 <- read.csv("data/trip_data/202111-divvy-tripdata.csv")
Dec_21 <- read.csv("data/trip_data/202112-divvy-tripdata.csv")
Jan_22 <- read.csv("data/trip_data/202201-divvy-tripdata.csv")
Feb_22 <- read.csv("data/trip_data/202202-divvy-tripdata.csv")
Mar_22 <- read.csv("data/trip_data/202203-divvy-tripdata.csv")
Apr_22 <- read.csv("data/trip_data/202204-divvy-tripdata.csv")
May_22 <- read.csv("data/trip_data/202205-divvy-tripdata.csv")

```

After importing the data, a check was made to compare the structure of all tables and find out if all column names and data types were aligned.

```{r eval=FALSE, results='hide'}
str(Jun_21)
str(Jul_21)
str(Aug_21)
str(Sep_21)
str(Oct_21)
str(Nov_21)
str(Dec_21)
str(Jan_22)
str(Feb_22)
str(Mar_22)
str(Apr_22)
```

It was concluded that all tables shared an equal structure, so no changes were required.
The tables were them merged into a single dataset.

```{r eval=FALSE, results='hide'}
trip_data <- bind_rows(
  Jun_21,
  Jul_21,
  Aug_21,
  Sep_21,
  Oct_21,
  Nov_21,
  Dec_21,
  Jan_22,
  Feb_22,
  Mar_22,
  Apr_22,
  May_22
)
```

After combining the datasets, the started_at and ended_at columns were changed from datatype char to datetime so the data could be sorted by date. The lubridate library and the arrange function were used for the effect.
Also using the lubridate library, columns “year”, “month”, “day” and “day_of_week” were created to enable different levels of aggregation.

```{r eval=FALSE, results='hide'}
library(lubridate)
trip_data$started_at <- ymd_hms(trip_data$started_at)
trip_data$ended_at <- ymd_hms(trip_data$ended_at)

# sort data by started_at
trip_data <- trip_data %>% 
  arrange(started_at)

# create day, month, year and day_of_week columns
trip_data$year <- year(trip_data$started_at)
trip_data$month <- month(trip_data$started_at)
trip_data$day <- day(trip_data$started_at)
trip_data$day_of_week <- wday(trip_data$started_at)
```

Next, a new column was created with the calculated ride length.
Checking the minimal ride length in the dataframe revealed there were negative numbers. Since data needed to be removed, a new dataframe was created without all rows with negative ride length.
It was also found that some rows contained empty station ids so those were removed.

```{r eval=FALSE, results='hide'}
# calculate ride_length
trip_data$ride_length <- difftime(trip_data$ended_at, trip_data$started_at, units = "secs")
trip_data$ride_length <- as.numeric(as.character(trip_data$ride_length))

# remove rows with negative ride length
trip_data_v2 <- trip_data %>% 
  filter(trip_data$ride_length > 0)

# remove empty station ids
trip_data_v2 <- trip_data_v2 %>% 
  filter(start_station_id != "") %>% 
  filter(end_station_id != "")
```

To further analyze station names and ids, a new dataframe was created with only the station_id and station_name columns.

Since the station df contains only 1045 rows, it was exported to a spreadsheet for simpler analysis.

```{r eval=FALSE, results='hide'}
# create station df
start_station_df <- trip_data_v2[c(5, 6)]
end_station_df <- trip_data_v2[c(7, 8)]
colnames(start_station_df) <- c("station_name", "station_id")
colnames(end_station_df) <- c("station_name", "station_id")
station_df <- bind_rows(start_station_df, end_station_df) %>% 
  distinct(station_id, .keep_all = TRUE) %>% 
  arrange(station_id)

write_csv(station_df,"station.csv")
```

It was found that the dataset includes several test stations and repair stations. Trips from or to these locations are not relevant for this analysis so they were filtered out.

Finally, a check was performed to see if the data contained any duplicate values for ride_id which should be unique. Since it had none, the clean dataset was saved to a new csv file.

```{r eval=FALSE, results='hide'}
# remove test and repair trips
trip_data_v2 <- trip_data_v2 %>% 
  filter(!str_detect(start_station_id, "test")) %>% 
  filter(!str_detect(start_station_id, "TEST")) %>%
  filter(!str_detect(start_station_id, "REPAIR")) %>%
  filter(!str_detect(start_station_id, "checking"))
  
# check for duplicates
sum(duplicated(trip_data_v2$ride_id))

# save cleaned dataset
write_csv(trip_data_v2,"trip_data_cleaned.csv")
```

## 4. Analysis

For the analysis phase it was decided that the key metrics to evaluate and compare between casual and member riders were the number of trips, the average trip duration, the distribution of rides during the week and throughout the year as well as the most popular time of day for each rider type. 

### 4.1 Number of trips and trip duration per rider type

```{r results='hide', message=FALSE}
library(tidyverse)
library(lubridate)
library(ggplot2)

trip_data <- read_csv('trip_data_cleaned.csv')

# ride length summary
summary(trip_data$ride_length)

# set day of week labels, correct day column to ymd, add week_num column
trip_data <- trip_data %>% 
  mutate(day_of_week=wday(started_at,label=TRUE, abbr=FALSE)) %>% 
  mutate(day = date(started_at)) %>% 
  mutate(week = isoweek(started_at))

# check ride length average per user type
ride_length_df <- trip_data %>% 
  group_by(member_casual, day) %>% 
  summarise(num_trips = n(), avg_trip_length = mean(ride_length), median_trip_length = median(ride_length))

# plot ride length chart
chart_1 <- ggplot(data = ride_length_df) +
  geom_point(mapping = aes(x = avg_trip_length, y = num_trips, colour = member_casual)) +
  scale_x_continuous(name = "Average trip length") +
  scale_y_continuous(name = "Number of trips") +
  scale_color_discrete(name = "") +
  labs(title = "Number of trips & trip length per user type")
```
```{r message=FALSE, results='hold', fig.align='center'}
chart_1
```

Chart 1 shows casual riders take longer trips and are less consistent on the number of trips per day. 
Members on the other hand are more consistent on the number of trips and average trip length. This is most likely tied to the fact that members use the Cyclist bikes for commuting to and from work.

### 4.2 Distribution of trips during the year

``` {r message=FALSE, results='hide'}
# create df that summarises the number of trips by date and the rider membership
hm_data <- trip_data %>% 
  select(day, day_of_week, week, month, year, member_casual) %>% 
  group_by(member_casual, day) %>% 
  mutate(num_trips = n()) %>% 
  distinct(day, member_casual, .keep_all = TRUE)

# create separate df for casual and member riders
hm_member <- hm_data %>% 
  filter(member_casual == "member")

hm_casual <- hm_data %>% 
  filter(member_casual == "casual")

# plot heatmap for member riders
chart_2 <- ggplot(data = hm_member) + 
  geom_tile(mapping = aes(x = week, y = day_of_week, fill = num_trips),colour = "white") +
  scale_fill_viridis_b(name = "Number of Trips") +
  scale_y_discrete(limits = rev) +
  scale_x_continuous(expand = c(0,0), breaks = seq(1, 52, length = 12),
                     labels = c("Jan", "Feb", "Mar", "Apr", "May", "Jun","Jul", "Aug", "Sep", "Oct", "Nov", "Dec")) +
  theme(axis.title = element_blank()) +
  labs(title = "Member Riders")

# plot heatmap for casual riders
chart_3 <- ggplot(data = hm_casual) + 
  geom_tile(mapping = aes(x = week, y = day_of_week, fill = num_trips),colour = "white") +
  scale_fill_viridis_b(name = "Number of Trips") +
  scale_y_discrete(limits = rev) +
  scale_x_continuous(expand = c(0,0), breaks = seq(1, 52, length = 12),
                     labels = c("Jan", "Feb", "Mar", "Apr", "May", "Jun","Jul", "Aug", "Sep", "Oct", "Nov", "Dec")) +
  theme(axis.title = element_blank()) +
  labs(title = "Casual Riders")

```
```{r message=FALSE, results='hold', fig.align='center'}
chart_2
chart_3
```

Charts 2 and 3 show that riders are more active during the summer months and confirm that member riders make more trips during weekdays whereas casual riders mainly ride on weekends.
Again the data seems to indicate member riders us the service mainly for commuting to work and casual riders use it mostly for leisure.

### 4.3 Time of day trip distribution

``` {r message=FALSE, results='hide'}

# create df grouping number of trips per time of day
tod_df <- trip_data %>% 
  mutate(hour = hour(started_at)) %>%
  group_by(hour, member_casual) %>% 
  summarise(num_trips = n()/1000)

# change hour order 
level_order <- c(6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 0, 1 ,2, 3, 4, 5)

# plot stacked bar chart displaying the number of trips per member type and time of day
chart_4 <- ggplot(data = tod_df) +
  geom_bar(mapping = aes(x = factor(tod_df$hour, level = level_order), y = tod_df$num_trips, fill=tod_df$member_casual),
           position = "stack",
           stat = "identity") +
  scale_x_discrete(name = "Time of day (hour)") + 
  scale_y_continuous(name = "Number of trips (k)") +
  scale_fill_discrete(name = "") +
  labs(title = "Most popular time of day")

```

```{r message=FALSE, results='hold', fig.align='center'}
chart_4

```

Chart 4 shows that members typically make more trips in the early morning or late afternoon, consistent with commuting to work.
Casual riders make more trips during the afternoon.

## 5. Recommendations

Since the main purpose of this analysis was to present the difference in behavior between casual and member riders, the main recommendations for converting casual riders to annual subscribers all lean on targeting casual riders who despite not paying for an annual memberships have the same pattern in behavior. 
Therefore, any marketing campaign should target riders who:

**- Make shorter trips**

**- Make more trips during the week**

**- Make more trips on the early morning and late afternoon**


  
  
